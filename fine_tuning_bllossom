!pip install -U accelerate==0.29.3 peft==0.10.0 bitsandbytes==0.43.1 transformers==4.40.0 trl==0.8.6 datasets==2.19.0

import torch
from datasets import load_dataset
from transformers import (BitsAndBytesConfig,
                          AutoTokenizer,
                          AutoModelForCausalLM,
                          TrainingArguments)
from peft import (LoraConfig,
                  get_peft_model,
                  prepare_model_for_kbit_training)
from trl import SFTTrainer

base_model = 'MLP-KTLim/llama-3-Korean-Bllossom-8B'


import pandas as pd
import json

# 엑셀 파일 읽기
excel_data = pd.read_excel('/content/뱅QA_프롬포트_수정_ .xlsx')

# JSON으로 변환
json_data = excel_data.to_json(orient='records', force_ascii=False, indent=4)

# 파일로 저장
with open('결과.json', 'w', encoding='utf-8') as f:
    f.write(json_data)

print('변환 완료! 결과.json 파일이 생성되었습니다.')


tokenizer = AutoTokenizer.from_pretrained(base_model)
tokenizer.pad_token = tokenizer.eos_token


# 보드게임QA dataset형식으로 변환

from datasets import Dataset
with open('결과.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# pandas DataFrame-> dictionary 리스트
data_dict = {
    'question': [item['Q'] for item in data],
    'answer': [item['A'] for item in data]
}

# dict -> Dataset 형식으로 변환
dataset = Dataset.from_dict(data_dict)

def preprocess(data):
    return data.map(
        lambda x: {
            'data': tokenizer.apply_chat_template(
                [
                    {"role": "system", "content": x['question']},
                    {"role": "assistant", "content": x['answer']}
                ],
                add_generation_prompt=False,
                tokenize=False,
                return_tensors="pt"
            )
        }
    ).map(
        lambda samples: tokenizer(samples["data"]),
        batched=True
    )

# 전처리 적용
processed_data = preprocess(dataset)


bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4"
    )
model = AutoModelForCausalLM.from_pretrained(
    base_model,
    quantization_config = bnb_config,
    device_map = 'auto',
    low_cpu_mem_usage=True
    )

lora_config = LoraConfig(
    r=4,
    lora_alpha=32,
    target_modules=["q_proj", "o_proj", "k_proj", "v_proj", "gate_proj", "up_proj", "down_proj"],
    lora_dropout=0.1,
    bias="none"
    )

model.gradient_checkpointing_enable()
model = prepare_model_for_kbit_training(model)
model = get_peft_model(model, lora_config)
model.print_trainable_parameters()


training_args = TrainingArguments(
    output_dir="./results",
    overwrite_output_dir=True,
    per_device_train_batch_size=8,
    gradient_accumulation_steps=8,
    num_train_epochs=30,
    learning_rate=2e-5,
    lr_scheduler_type="cosine",
    warmup_steps=500,
    weight_decay=0.01,
    fp16=True,
    logging_steps=50,
    save_steps=500,
    save_total_limit=2,
    dataloader_num_workers=2,
    report_to="none",
    max_steps=800
    )

trainer = SFTTrainer(
    model=model,
    train_dataset=data,
    peft_config=lora_config,
    dataset_text_field="data",
    tokenizer=tokenizer,
    args=training_args,
    max_seq_length='NONE',
    packing=False,
    )

model.config.use_cache = False
trainer.train()



PROMPT = '''You are a helpful AI assistant. Please answer the user's questions kindly. 당신은 유능한 AI 어시스턴트 입니다. 사용자의 질문에 대해 친절하게 답변해주세요.'''
instruction = '''
뱅이라는 보드게임에서 야생마 카드를 버리거나 교체할 수 있는 조건은 무엇인가요?

'''

messages = [
    {"role": "system", "content": f"{PROMPT}"},
    {"role": "user", "content": f"{instruction}"}
    ]

input_ids = tokenizer.apply_chat_template(
    messages,
    add_generation_prompt=True,
    return_tensors="pt"
).to(model.device)

terminators = [
    tokenizer.eos_token_id,
    tokenizer.convert_tokens_to_ids("<|eot_id|>")
]

outputs = model.generate(
    input_ids,
    max_new_tokens=256,
    eos_token_id=terminators,
    do_sample=True,
    temperature=0.5,
    top_p=0.8,
    repetition_penalty = 1.1
)

print(tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True))
